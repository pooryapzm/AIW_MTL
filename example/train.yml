batch_size: '32'
data: path/to/task1,path/to/task2
dec_layers: '3'
decay_method: performance
decoder_type: rnn
dropout: 0.3
enc_layers: '3'
encoder_type: rnn
epochs: '25'
gpu_ranks: 0
input_feed: 1
keep_checkpoint: 1
learning_rate: '0.001'
max_grad_norm: 5
meta_batch_weighting: '1'
meta_batch_weighting_mode: '1'
meta_mtl_concat_mode: psuedo
meta_step_report: 50
mtl_fully_share: '0'
mtl_gamma: 1,1,1,1
mtl_schedule: '1'
mtl_shared_optimizer: 0
mtl_shared_vocab: '0'
mtl_shared_vocab_path: path/to/shared/vocab 
normalization: none
normalize_meta_loss: 1
optim: adam
report_every: 100
rnn_size: 512
rnn_type: LSTM
save_model: ./checkpoints/model
seed: 12345
share_decoder_bottom: 1
share_encoder_bottom: 0
shared_dec_layers: 2
shared_enc_layers: 1
warm_model: ''
word_vec_size: 512
